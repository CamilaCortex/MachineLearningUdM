# 1.4 CRISP-DM: MetodologÃ­a para Proyectos de ML

> **Objetivo**: Aprender a estructurar proyectos de ML usando la metodologÃ­a estÃ¡ndar de la industria.

## ğŸ“– IntroducciÃ³n

**CRISP-DM** (Cross-Industry Standard Process for Data Mining) es la metodologÃ­a mÃ¡s utilizada en la industria para proyectos de Machine Learning y Data Science. Fue creada en 1996 y sigue siendo el estÃ¡ndar de facto porque proporciona un marco estructurado y probado.

## ğŸ”„ Las 6 Fases de CRISP-DM

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 1. ComprensiÃ³n del  â”‚
    â”‚    Negocio          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 2. ComprensiÃ³n de   â”‚
    â”‚    los Datos        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 3. PreparaciÃ³n de   â”‚
    â”‚    Datos            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 4. Modelado         â”‚â—„â”€â”€â”
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
               â”‚               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚ 5. EvaluaciÃ³n       â”‚â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 6. Despliegue       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1ï¸âƒ£ ComprensiÃ³n del Negocio

**Objetivo**: Definir claramente el problema y los objetivos del proyecto.

#### Preguntas Clave

- Â¿QuÃ© problema de negocio estamos resolviendo?
- Â¿Realmente necesitamos ML para esto?
- Â¿CÃ³mo mediremos el Ã©xito?
- Â¿CuÃ¡l es el impacto esperado?

#### Ejemplo PrÃ¡ctico

```python
# Documento de proyecto: Sistema de predicciÃ³n de churn

PROBLEMA_NEGOCIO = {
    'descripcion': 'Clientes abandonan el servicio sin previo aviso',
    'impacto_actual': 'PÃ©rdida de $500K mensuales',
    'objetivo': 'Predecir quÃ© clientes estÃ¡n en riesgo de irse',
    'metrica_exito': 'Reducir churn en 20% en 6 meses',
    'necesita_ml': True,  # Patrones complejos, muchos datos
    'alternativas_evaluadas': ['Reglas simples', 'AnÃ¡lisis manual']
}

# Criterios de Ã©xito medibles
METRICAS_NEGOCIO = {
    'precision_minima': 0.75,  # 75% de predicciones correctas
    'recall_minimo': 0.60,     # Detectar 60% de churners
    'tiempo_respuesta': '< 100ms',
    'costo_falso_positivo': '$10',  # Costo de retener cliente que no se irÃ­a
    'costo_falso_negativo': '$500'  # Costo de perder cliente
}
```

### 2ï¸âƒ£ ComprensiÃ³n de los Datos

**Objetivo**: Explorar y entender los datos disponibles.

#### Actividades

```python
import pandas as pd
import matplotlib.pyplot as plt

# Cargar datos
df = pd.read_csv('clientes.csv')

# 1. ExploraciÃ³n inicial
print(f"Filas: {len(df)}, Columnas: {len(df.columns)}")
print(df.info())
print(df.describe())

# 2. Verificar calidad
print(f"\nValores nulos:\n{df.isnull().sum()}")
print(f"\nDuplicados: {df.duplicated().sum()}")

# 3. AnÃ¡lisis de distribuciÃ³n del target
print(f"\nDistribuciÃ³n de churn:")
print(df['churn'].value_counts(normalize=True))

# 4. Visualizar relaciones
df.groupby('churn')['meses_cliente'].mean().plot(kind='bar')
plt.title('Meses promedio por grupo')
plt.show()

# 5. Identificar problemas
PROBLEMAS_DATOS = {
    'valores_nulos': df.isnull().sum().sum(),
    'desbalanceo_clases': df['churn'].value_counts()[1] / len(df),
    'outliers_detectados': True,
    'necesita_mas_datos': len(df) < 10000
}
```

#### Checklist de Calidad de Datos

- âœ… Â¿Tenemos suficientes datos? (mÃ­nimo 1000 ejemplos)
- âœ… Â¿Los datos son representativos?
- âœ… Â¿Hay valores nulos o inconsistentes?
- âœ… Â¿Las clases estÃ¡n balanceadas?
- âœ… Â¿Necesitamos datos adicionales?

### 3ï¸âƒ£ PreparaciÃ³n de Datos

**Objetivo**: Transformar datos crudos en formato listo para ML.

#### Pipeline de PreparaciÃ³n

```python
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline

# 1. Limpieza
def limpiar_datos(df):
    # Eliminar duplicados
    df = df.drop_duplicates()
    
    # Corregir tipos de datos
    df['fecha_registro'] = pd.to_datetime(df['fecha_registro'])
    
    # Eliminar outliers extremos
    Q1 = df['gasto_mensual'].quantile(0.25)
    Q3 = df['gasto_mensual'].quantile(0.75)
    IQR = Q3 - Q1
    df = df[~((df['gasto_mensual'] < (Q1 - 3 * IQR)) | 
              (df['gasto_mensual'] > (Q3 + 3 * IQR)))]
    
    return df

# 2. Feature Engineering
def crear_features(df):
    # Features temporales
    df['dias_desde_registro'] = (pd.Timestamp.now() - df['fecha_registro']).dt.days
    df['mes_registro'] = df['fecha_registro'].dt.month
    
    # Features de comportamiento
    df['gasto_por_mes'] = df['gasto_total'] / df['meses_cliente']
    df['llamadas_por_mes'] = df['llamadas_soporte'] / df['meses_cliente']
    
    # Features categÃ³ricas
    df = pd.get_dummies(df, columns=['plan_tipo', 'region'])
    
    return df

# 3. Pipeline completo
preprocessing_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# Aplicar
df_limpio = limpiar_datos(df)
df_features = crear_features(df_limpio)
X = df_features.drop('churn', axis=1)
y = df_features['churn']
X_procesado = preprocessing_pipeline.fit_transform(X)
```

### 4ï¸âƒ£ Modelado

**Objetivo**: Entrenar y comparar diferentes modelos.

```python
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

# Probar mÃºltiples modelos
modelos = {
    'Logistic Regression': LogisticRegression(),
    'Random Forest': RandomForestClassifier(n_estimators=100),
    'Gradient Boosting': GradientBoostingClassifier()
}

resultados = {}
for nombre, modelo in modelos.items():
    scores = cross_val_score(modelo, X_procesado, y, cv=5, scoring='f1')
    resultados[nombre] = {
        'f1_mean': scores.mean(),
        'f1_std': scores.std()
    }
    print(f"{nombre}: F1={scores.mean():.3f} (+/- {scores.std():.3f})")

# Seleccionar mejor modelo
mejor_modelo = max(resultados, key=lambda x: resultados[x]['f1_mean'])
print(f"\nğŸ† Mejor modelo: {mejor_modelo}")
```

### 5ï¸âƒ£ EvaluaciÃ³n

**Objetivo**: Validar que el modelo resuelve el problema de negocio.

```python
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

# Entrenar modelo final
modelo_final = GradientBoostingClassifier()
modelo_final.fit(X_train, y_train)

# Predecir en test set
y_pred = modelo_final.predict(X_test)
y_proba = modelo_final.predict_proba(X_test)[:, 1]

# MÃ©tricas tÃ©cnicas
print("Reporte de ClasificaciÃ³n:")
print(classification_report(y_test, y_pred))

# Matriz de confusiÃ³n
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d')
plt.title('Matriz de ConfusiÃ³n')
plt.show()

# EvaluaciÃ³n de negocio
def evaluar_impacto_negocio(y_true, y_pred):
    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
    
    # Costos
    costo_fp = fp * 10   # $10 por falso positivo
    costo_fn = fn * 500  # $500 por falso negativo
    ahorro_tp = tp * 500 # $500 ahorrado por cada churn detectado
    
    roi = ahorro_tp - (costo_fp + costo_fn)
    
    return {
        'clientes_salvados': tp,
        'costo_total': costo_fp + costo_fn,
        'ahorro_total': ahorro_tp,
        'roi': roi,
        'roi_mensual': roi
    }

impacto = evaluar_impacto_negocio(y_test, y_pred)
print(f"\nğŸ’° ROI Estimado: ${impacto['roi']:,.0f}/mes")
```

#### Preguntas de EvaluaciÃ³n

- âœ… Â¿El modelo cumple las mÃ©tricas tÃ©cnicas?
- âœ… Â¿Resuelve el problema de negocio?
- âœ… Â¿El ROI justifica la inversiÃ³n?
- âœ… Â¿Es mejor que la soluciÃ³n actual?
- âœ… Â¿Es interpretable para stakeholders?

### 6ï¸âƒ£ Despliegue

**Objetivo**: Poner el modelo en producciÃ³n.

```python
import joblib
from flask import Flask, request, jsonify

# 1. Guardar modelo
joblib.dump(modelo_final, 'modelo_churn_v1.pkl')
joblib.dump(preprocessing_pipeline, 'pipeline_v1.pkl')

# 2. API de predicciÃ³n
app = Flask(__name__)

modelo = joblib.load('modelo_churn_v1.pkl')
pipeline = joblib.load('pipeline_v1.pkl')

@app.route('/predict', methods=['POST'])
def predecir_churn():
    # Recibir datos
    datos_cliente = request.json
    
    # Preparar features
    X_nuevo = pd.DataFrame([datos_cliente])
    X_procesado = pipeline.transform(X_nuevo)
    
    # Predecir
    probabilidad = modelo.predict_proba(X_procesado)[0][1]
    prediccion = 'alto_riesgo' if probabilidad > 0.7 else 'bajo_riesgo'
    
    return jsonify({
        'cliente_id': datos_cliente['id'],
        'riesgo_churn': prediccion,
        'probabilidad': float(probabilidad),
        'accion_recomendada': 'contactar_retencion' if probabilidad > 0.7 else 'monitorear'
    })

# 3. Monitoreo
def monitorear_modelo():
    """Verificar performance en producciÃ³n"""
    predicciones_mes = cargar_predicciones_mes_actual()
    resultados_reales = cargar_resultados_reales()
    
    precision_actual = calcular_precision(predicciones_mes, resultados_reales)
    
    if precision_actual < 0.70:  # Umbral de alerta
        enviar_alerta("âš ï¸ Modelo degradado - reentrenar")
```

## ğŸ”„ Naturaleza Iterativa

CRISP-DM no es lineal. Constantemente vuelves a fases anteriores:

```python
# Ciclo tÃ­pico de iteraciÃ³n
iteracion = 1
while not modelo_satisfactorio:
    print(f"\n=== IteraciÃ³n {iteracion} ===")
    
    # Modelado
    modelo = entrenar_modelo(X_train, y_train)
    
    # EvaluaciÃ³n
    metricas = evaluar_modelo(modelo, X_test, y_test)
    
    if metricas['f1'] < 0.75:
        # Volver a preparaciÃ³n de datos
        print("âŒ MÃ©tricas bajas - mejorar features")
        X_train, X_test = agregar_nuevas_features(X_train, X_test)
    elif metricas['roi'] < 50000:
        # Volver a comprensiÃ³n de negocio
        print("âŒ ROI bajo - revisar objetivos")
        ajustar_umbrales_decision()
    else:
        print("âœ… Modelo satisfactorio")
        modelo_satisfactorio = True
    
    iteracion += 1
```

## ğŸ¯ Puntos Clave

âœ… **CRISP-DM estructura proyectos de ML** de principio a fin

âœ… **6 fases**: Negocio â†’ Datos â†’ PreparaciÃ³n â†’ Modelado â†’ EvaluaciÃ³n â†’ Despliegue

âœ… **Es iterativo**: Vuelves a fases anteriores segÃºn resultados

âœ… **Enfoque en negocio**: No solo mÃ©tricas tÃ©cnicas, tambiÃ©n ROI

âœ… **DocumentaciÃ³n**: Cada fase debe estar documentada

## ğŸ’¡ Consejos PrÃ¡cticos

1. **Empieza simple**: Modelo baseline primero
2. **Itera rÃ¡pido**: Ciclos cortos de 1-2 semanas
3. **Mide siempre**: MÃ©tricas tÃ©cnicas Y de negocio
4. **Comunica**: Actualiza stakeholders regularmente
5. **Documenta**: Decisiones y experimentos

## ğŸ”„ PrÃ³ximos Pasos

En la siguiente lecciÃ³n profundizaremos en el **Proceso de SelecciÃ³n de Modelos**, una parte crÃ­tica de la fase de Modelado.

## ğŸ’¬ Notas de la Comunidad

* [Notas de Peter Ernicke](https://knowmledge.com/2023/09/12/ml-zoomcamp-2023-introduction-to-machine-learning-part-4/)
* **Comparte tu experiencia** - Â¿QuÃ© fase te resulta mÃ¡s desafiante?

---

**ğŸ“– Material base**: Adaptado del [ML Zoomcamp](https://github.com/DataTalksClub/machine-learning-zoomcamp) por Alexey Grigorev y DataTalks.Club

---

[â¬…ï¸ Anterior: ML Supervisado](03-supervised-ml.md) | [Volver al Ã­ndice](README.md) | [Siguiente: SelecciÃ³n de Modelos â¡ï¸](05-model-selection.md)

